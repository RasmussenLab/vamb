{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step three: Train the autoencoder and encode input data\n",
    "\n",
    "Again, you can use `help` to see how to use the module\n",
    "\n",
    "`>>> help(vamb.encode)`\n",
    "\n",
    "    Help on module vamb.encode in vamb:\n",
    "\n",
    "    NAME\n",
    "        vamb.encode - Encode a depths matrix and a tnf matrix to latent representation.\n",
    "\n",
    "    DESCRIPTION\n",
    "        Creates a variational autoencoder in PyTorch and tries to represent the depths\n",
    "        and tnf in the latent space under gaussian noise.\n",
    "\n",
    "        usage:\n",
    "        >>> vae, dataloader = trainvae(depths, tnf) # Make & train VAE on Numpy arrays\n",
    "        >>> latent = vae.encode(dataloader) # Encode to latent representation\n",
    "        >>> latent.shape\n",
    "        (183882, 40)\n",
    "        \n",
    "    [ lines elided ]\n",
    "    \n",
    "---\n",
    "Aha, so we need to use the `trainvae` function first, then the `VAE.encode` method. You can call the `help` functions on those, but I'm not showing that here.\n",
    "\n",
    "Training networks always take some time. If you have a GPU and CUDA installed, you can pass `cuda=True` to `encode.trainvae` to train on your GPU for increased speed. With a beefy GPU, this can make quite a difference. I run this on my laptop, so I'll just use my CPU.\n",
    "\n",
    "Sometimes, you'll want to reuse a VAE you have already trained. For this, I've added the `VAE.save` method of the VAE class, as well as a `VAE.load` method. In this example, I'll write the trained model weights to a file in `/tmp` and show how to reload the VAE again. But remember - a trained VAE only works on the dataset it's been trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we import stuff\n",
    "import sys\n",
    "sys.path.append('/home/jakni/Documents/scripts/')\n",
    "import vamb\n",
    "\n",
    "# And load the data we just saved in tutorial part 1 - of course, if this was\n",
    "# the same notebook, we could have just kept it in memory\n",
    "with open('/home/jakni/Downloads/example/rpkms.npz', 'rb') as file:\n",
    "    rpkms = vamb.vambtools.read_npz(file)\n",
    "    \n",
    "with open('/home/jakni/Downloads/example/tnfs.npz', 'rb') as file:\n",
    "    tnfs = vamb.vambtools.read_npz(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tErrorsum: 1000\n",
      "\tMSE ratio: 0.2\n",
      "\tCUDA: False\n",
      "\tN latent: 40\n",
      "\tN hidden: 325, 325\n",
      "\tN contigs: 39551\n",
      "\tN samples: 6\n",
      "\tN epochs: 5\n",
      "\tBatch size: 128\n",
      "\n",
      "\tEpoch: 1\tLoss: 14520.8\tCE: 5.38282\tMSE: 1.00173\tKLD: 0.42735\n",
      "\tEpoch: 2\tLoss: 10773.4\tCE: 3.98606\tMSE: 0.94358\tKLD: 0.71098\n",
      "\tEpoch: 3\tLoss: 9909.4\tCE: 3.66427\tMSE: 0.92106\tKLD: 0.92786\n",
      "\tEpoch: 4\tLoss: 9499.4\tCE: 3.51189\tMSE: 0.90177\tKLD: 1.10762\n",
      "\tEpoch: 5\tLoss: 9235.8\tCE: 3.41405\tMSE: 0.88542\tKLD: 1.28936\n"
     ]
    }
   ],
   "source": [
    "# I'm training just 5 epochs for this demonstration.\n",
    "# When actually using the VAE, 200-300 epochs are suitable\n",
    "with open('/tmp/model.pt', 'wb') as modelfile:\n",
    "    vae, dataloader = vamb.encode.trainvae(rpkms, tnfs, nepochs=5, modelfile=modelfile, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The VAE encodes the high-dimensional (n_samples + 136 features) input data in a lower dimensional space (nlatent features). When training, it learns an encoding scheme, with which it encodes the input data to a series of normal distributions, and a decoding scheme, in which it uses one value sampled from each normal distribution to reconstruct the input data given the latent representation while influenced by gaussian noise.\n",
    "\n",
    "The theory here is that the latent representation is a more efficient encoding of the input data. If the input data for the contigs indeed do fall into bins, an efficient encoding would be to simply encode the bin they belong to, then use the \"bin identity\" to reconstruct the data. We force it to encode to *distributions* rather than single values because this makes it more robust - it will not as easily overfit to interpret slightly different values as being very distinct if there is an intrinsic noise in each encoding.\n",
    "\n",
    "The loss of the VAE is the sum of three measures:\n",
    "\n",
    "* Cross entropy (CE) measures the dissimilarity of the reconstructed abundances to observed abundances\n",
    "* Mean squared error (MSE) measures the dissimilary of reconstructed versus observed TNF\n",
    "* Kullback-Leibler divergence (KLD) measures the dissimilarity between the encoded distributions and the standard gaussian distribution N(0, 1)\n",
    "\n",
    "The latter term is standard in VAEs, and indudes the VAE to not crazily overfit by imposing some sensible prior on the kind of encodings it can choose.\n",
    "\n",
    "These terms are weigthed with the keyword arguments `errorsum` and `msefraction`. These numbers adjusts CE and MSE for a naïve network such that CE+MSE = `errorsum` and MSE/(CE+MSE) = `msefraction`. A naïve networks predicts MSE ~ N(0,1) and depth = 1/n_samples for every contig. Such a naïve network has an expected uncorrected CE of log(n_samples)/n_samples and an expected MSE of 2. Broadly speaking, `errorsum` gauges how much the network is allowed to learn - a low value constrains the latent layer to its prior - and `msefraction` gauges how much the network cares about TNF as opposed to depth.\n",
    "\n",
    "We can see the KL-divergence rises as it learns the dataset and the latent layer drifts away from its prior. At some point, it will begin to overfit too much, and the penalty associated with KL-divergence outweighs the CE and MSE losses. At this point, the KL will stall, and then fall. This point depends on the errorsum and the complexity of the dataset.\n",
    "\n",
    "Okay, so now we have the trained `vae` and the `dataloader`. Let's feed the dataloader to the VAE in order to get the latent representation:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39551, 40)\n"
     ]
    }
   ],
   "source": [
    "# No need to pass gpu=True to the encode function to encode on GPU\n",
    "# If you trained the VAE on GPU, it already resides there\n",
    "latent = vae.encode(dataloader)\n",
    "\n",
    "print(latent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "That's 39551 contigs each represented by the (non-noisy) value of 40 latent neurons.\n",
    "\n",
    "Now we need to cluster this. That's for the next notebook, so again, I'll save the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jakni/Downloads/example/latent.npz', 'wb') as file:\n",
    "    vamb.vambtools.write_npz(file, latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Alright, let me show how to load the trained VAE given the model file we made above.\n",
    "\n",
    "I want to **show** that we get the same network back that we trained, so let's try to feed it the same data twice.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Manually create the first mini-batch without randomization\n",
    "rpkms_in = torch.Tensor(rpkms[:128]).reshape((128, -1))\n",
    "tnfs_in = torch.Tensor(tnfs[:128]).reshape((128, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6341,  0.8006, -1.2837,  2.2479,  3.0842,  2.0184,  0.3096,\n",
      "        -0.7320,  1.7008, -0.8898,  2.0501,  0.4636, -0.8683,  0.4024,\n",
      "        -1.2859,  0.3301,  0.8071, -1.0957,  0.4424, -1.1223, -0.7120,\n",
      "        -2.1790, -1.9727, -0.8413, -2.6715, -1.0463, -1.6019, -1.8441,\n",
      "         1.7171,  0.3378, -0.8309,  1.1683,  2.1508, -2.0515, -0.3983,\n",
      "        -0.4869, -1.5248, -1.6428,  2.3076, -1.4227])\n"
     ]
    }
   ],
   "source": [
    "# Calling the VAE as a function encodes and decodes the arguments,\n",
    "# returning the outputs and the two distribution layers\n",
    "depths_out, tnf_out, mu, logsigma = vae(rpkms_in, tnfs_in)\n",
    "print(mu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6341,  0.8006, -1.2837,  2.2479,  3.0842,  2.0184,  0.3096,\n",
      "        -0.7320,  1.7008, -0.8898,  2.0501,  0.4636, -0.8683,  0.4024,\n",
      "        -1.2859,  0.3301,  0.8071, -1.0957,  0.4424, -1.1223, -0.7120,\n",
      "        -2.1790, -1.9727, -0.8413, -2.6715, -1.0463, -1.6019, -1.8441,\n",
      "         1.7171,  0.3378, -0.8309,  1.1683,  2.1508, -2.0515, -0.3983,\n",
      "        -0.4869, -1.5248, -1.6428,  2.3076, -1.4227])\n"
     ]
    }
   ],
   "source": [
    "# Now, delete the VAE\n",
    "del vae\n",
    "\n",
    "# And reload it:\n",
    "# We need to manually specify whether it should use GPU or not\n",
    "# And whether the network show begin in training or evaluation mode.\n",
    "vae = vamb.encode.VAE.load('/tmp/model.pt', cuda=False, evaluate=True)\n",
    "depths_out, tnf_out, mu, logsigma = vae(rpkms_in, tnfs_in)\n",
    "print(mu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We get the same values back, meaning the saved network is the same as the loaded network!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
